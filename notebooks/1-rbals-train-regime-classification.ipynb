{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os, glob\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Add the path to the src folder to the path\n",
    "module_path = os.path.abspath(os.path.join('../src/'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load and crop images\n",
    "\n",
    "We assume that the \"Qflow2.0\" dataset are stored in the `data/raw/` directory. The link to the dataset is provided in the `data/external` folder.\n",
    "We also assume that you want to only train a model for state regime detection on the \"Qflow2.0\" dataset(the sim_normal data is for that).\n",
    "This cell is supposed to be run only once if save_data is set to True.\n",
    "The cropped images are stored in the `data/interim/` directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from ml_tools.data.subimage_generator import SubImageGenerator\n",
    "\n",
    "# # Set up the path to the data\n",
    "# data_path = '../data/raw/data_qflow_v2/simulated/sim_normal/'\n",
    "# data_files = glob.glob(data_path + '*.hdf5')\n",
    "\n",
    "# for raw_data_file in data_files:\n",
    "#     generator = SubImageGenerator(border_margin=20)\n",
    "\n",
    "#     cropped_data = generator.generate_multiple_sub_images(\n",
    "#         raw_data_file, save_images=True, return_images=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load subimages and create a dataset for training\n",
    "The current step we need to do is data preparation. We need to load the subimages, make the preleminary modifications and create a dataset for training and testing. For that we will use an instance of the DatasetPreparation class. We need to specify here what type of label we want. Options are 'state' or 'data_quality' depending on what we want to train the model for. If we want to save the dataset you need to specify the path where you want to save it(it should be in data/interim/).You can specify a single .npz file,a whole directory(you must set the flag use_all_data) or the whole dataset in dictonary form from the cell above.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from ml_tools.preprocessing.dataset_preparator import DatasetPreparator\n",
    "\n",
    "# subimage_folder_path = '../data/interim/data_qflow_v2/simulated/sim_normal/'\n",
    "\n",
    "# preparator = DatasetPreparator(seed=42)\n",
    "\n",
    "# train_data, train_labels, validation_data, validation_labels = preparator.prepare_dataset(\n",
    "#                         path_or_dict=subimage_folder_path,\n",
    "#                         save_path=\"../data/interim/data_qflow_v2/simulated/\",\n",
    "#                         train_validation_split=0.75, \n",
    "#                         label_key_name='state', \n",
    "#                         )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot a few images to check if everything is ok"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Plot a few images to check if everything is ok\n",
    "# fig, ax = plt.subplots(1, 3, figsize=(15, 5))\n",
    "# ax[0].imshow(train_data[0, :, :, 0])\n",
    "# ax[1].imshow(train_data[1, :, :, 0])\n",
    "# ax[2].imshow(train_data[2, :, :, 0])\n",
    "# plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocess the data\n",
    "Now that we have the dataset created we need to preprocess it. For that we will use an instance of the SubImagePreprocessor class. The preprocessed dataset should be saved in the data/processed/ directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from ml_tools.preprocessing.subimage_preprocessor import SubImagePreprocessor\n",
    "\n",
    "\n",
    "# # Define the path to the dataset\n",
    "# dataset_path = '../data/interim/data_qflow_v2/simulated/unprocessed_dataset/'\n",
    "\n",
    "# # Load training data and labels\n",
    "# train_data_path = dataset_path + 'training/training_data.npz'\n",
    "# train_labels_path = dataset_path + 'training/training_labels.npz'\n",
    "# validation_data_path = dataset_path + 'validation/validation_data.npz'\n",
    "# validation_labels_path = dataset_path + 'validation/validation_labels.npz'\n",
    "\n",
    "# train_data = np.load(train_data_path)['training_data']\n",
    "# train_labels = np.load(train_labels_path)['training_labels']\n",
    "# validation_data = np.load(validation_data_path)['validation_data']\n",
    "# validation_labels = np.load(validation_labels_path)['validation_labels']\n",
    "\t\n",
    "# preprocessor = SubImagePreprocessor(\n",
    "#     auto_invert=False,\n",
    "#     noise_reduction=[],\n",
    "#     clip_value=None,\n",
    "#     cutoff_value= None\n",
    "# )\n",
    "\n",
    "# save_path = '../data/processed/data_qflow_v2/simulated/'\n",
    "\n",
    "# processed_train_data, proccessed_train_labels = preprocessor.preprocess_subimages(\n",
    "#     train_data,\n",
    "#     train_labels,\n",
    "#     train_or_validation='training',\n",
    "#     save_path=save_path\n",
    "#     )\n",
    "# processed_validation_data,processed_validation_labels = preprocessor.preprocess_subimages(\n",
    "#     validation_data,\n",
    "#     validation_labels,\n",
    "#     train_or_validation='validation',\n",
    "#     save_path=save_path\n",
    "#     )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Plot a few images at random\n",
    "# # Generate 3 random index\n",
    "# random_idx = np.random.randint(0, train_data.shape[0], 3)\n",
    "# fig, ax = plt.subplots(1, 3, figsize=(15, 5))\n",
    "# ax[0].set_title('label:'+str(train_labels[random_idx[0]]))\n",
    "# ax[1].set_title('label:'+str(train_labels[random_idx[1]]))\n",
    "# ax[2].set_title('label:'+str(train_labels[random_idx[2]]))\n",
    "# ax[0].imshow(processed_train_data[random_idx[0], :, :, 0])\n",
    "# ax[1].imshow(processed_train_data[random_idx[1], :, :, 0])\n",
    "# ax[2].imshow(processed_train_data[random_idx[2], :, :, 0])\n",
    "# # Plot the original images \n",
    "# fig, ax = plt.subplots(1, 3, figsize=(15, 5))\n",
    "# ax[0].imshow(train_data[random_idx[0], :, :, 0])\n",
    "# ax[1].imshow(train_data[random_idx[1], :, :, 0])\n",
    "# ax[2].imshow(train_data[random_idx[2], :, :, 0])\n",
    "# # Plot the labels as titles \n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model creation and training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of training data:  (72905, 30, 30, 1)\n",
      "Shape of training labels:  (72905, 5)\n",
      "Shape of validation data:  (24130, 30, 30, 1)\n",
      "Shape of validation labels:  (24130, 5)\n"
     ]
    }
   ],
   "source": [
    "# Define the path to the dataset\n",
    "dataset_path = '../data/processed/data_qflow_v2/simulated/processed_dataset/'\n",
    "\n",
    "# Load training data and labels\n",
    "train_data_path = dataset_path + 'training/processed_training_data.npz'\n",
    "train_labels_path = dataset_path + 'training/processed_training_labels.npz'\n",
    "train_data = np.load(train_data_path)['data']\n",
    "train_labels = np.load(train_labels_path)['labels']\n",
    "\n",
    "validation_data_path = dataset_path + 'validation/processed_validation_data.npz'\n",
    "validation_labels_path = dataset_path + 'validation/processed_validation_labels.npz'\n",
    "validation_data = np.load(validation_data_path)['data']\n",
    "validation_labels = np.load(validation_labels_path)['labels']\n",
    "\n",
    "print(\"Shape of training data: \", train_data.shape)\n",
    "print(\"Shape of training labels: \", train_labels.shape)\n",
    "print(\"Shape of validation data: \", validation_data.shape)\n",
    "print(\"Shape of validation labels: \", validation_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_transpose = np.transpose(train_data, (0, 3, 1, 2))\n",
    "validation_data_transpose = np.transpose(validation_data, (0, 3, 1, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/local/rbals/miniconda3/envs/colibri/lib/python3.10/site-packages/lightning_fabric/plugins/environments/slurm.py:168: PossibleUserWarning: The `srun` command is available on your system but is not used. HINT: If your intention is to run Lightning on SLURM, prepend your python command with `srun` like so: srun python /local/rbals/miniconda3/envs/colibri/lib/python3.10/ ...\n",
      "  rank_zero_warn(\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "StateEstimator(\n",
      "  (features): Sequential(\n",
      "    (0): Conv2d(1, 22, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3))\n",
      "    (1): BatchNorm2d(22, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): Dropout(p=0.655, inplace=False)\n",
      "    (3): ReLU()\n",
      "    (4): Conv2d(22, 22, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3))\n",
      "    (5): BatchNorm2d(22, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (6): Dropout(p=0.655, inplace=False)\n",
      "    (7): ReLU()\n",
      "    (8): Conv2d(22, 35, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3))\n",
      "    (9): BatchNorm2d(35, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (10): Dropout(p=0.194, inplace=False)\n",
      "    (11): ReLU()\n",
      "    (12): Conv2d(35, 35, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3))\n",
      "    (13): BatchNorm2d(35, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (14): Dropout(p=0.194, inplace=False)\n",
      "    (15): ReLU()\n",
      "  )\n",
      "  (global_avg_pool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "  (fc): Linear(in_features=35, out_features=5, bias=True)\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/local/rbals/miniconda3/envs/colibri/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/logger_connector.py:67: UserWarning: Starting from v1.9.0, `tensorboardX` has been removed as a dependency of the `pytorch_lightning` package, due to potential conflicts with other packages in the ML ecosystem. For this reason, `logger=True` will use `CSVLogger` as the default logger, unless the `tensorboard` or `tensorboardX` packages are found. Please `pip install lightning[extra]` or one of them to enable TensorBoard support by default\n",
      "  warning_cache.warn(\n",
      "/local/rbals/miniconda3/envs/colibri/lib/python3.10/site-packages/lightning_fabric/plugins/environments/slurm.py:168: PossibleUserWarning: The `srun` command is available on your system but is not used. HINT: If your intention is to run Lightning on SLURM, prepend your python command with `srun` like so: srun python /local/rbals/miniconda3/envs/colibri/lib/python3.10/ ...\n",
      "  rank_zero_warn(\n",
      "You are using a CUDA device ('NVIDIA GeForce RTX 3090') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name            | Type              | Params\n",
      "------------------------------------------------------\n",
      "0 | features        | Sequential        | 122 K \n",
      "1 | global_avg_pool | AdaptiveAvgPool2d | 0     \n",
      "2 | fc              | Linear            | 180   \n",
      "------------------------------------------------------\n",
      "123 K     Trainable params\n",
      "0         Non-trainable params\n",
      "123 K     Total params\n",
      "0.492     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sanity Checking DataLoader 0:   0%|          | 0/2 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/local/rbals/miniconda3/envs/colibri/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:490: PossibleUserWarning: Your `val_dataloader`'s sampler has shuffling enabled, it is strongly recommended that you turn shuffling off for val/test dataloaders.\n",
      "  rank_zero_warn(\n",
      "/local/rbals/miniconda3/envs/colibri/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:442: PossibleUserWarning: The dataloader, val_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 24 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                           "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/local/rbals/miniconda3/envs/colibri/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:442: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 24 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19: 100%|██████████| 1140/1140 [00:23<00:00, 47.80it/s, v_num=0] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=20` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19: 100%|██████████| 1140/1140 [00:23<00:00, 47.67it/s, v_num=0]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023/09/27 01:35:14 WARNING mlflow.utils.autologging_utils: MLflow autologging encountered a warning: \"/local/rbals/miniconda3/envs/colibri/lib/python3.10/site-packages/_distutils_hack/__init__.py:33: UserWarning: Setuptools is replacing distutils.\"\n"
     ]
    }
   ],
   "source": [
    "from pytorch_lightning import Trainer\n",
    "import mlflow\n",
    "import torch\n",
    "\n",
    "from ml_tools.models.state_estimator import StateEstimator\n",
    "from ml_tools.models.model_utils import prepare_dataloader\n",
    "\n",
    "\n",
    "# Auto log all the parameters, metrics, and models\n",
    "mlflow.pytorch.autolog()\n",
    "\n",
    "train_dataloader = prepare_dataloader(train_data_transpose, train_labels, batch_size=64, seed=42)\n",
    "val_dataloader = prepare_dataloader(validation_data_transpose, validation_labels, batch_size=64, seed=42)\n",
    "\n",
    "model = StateEstimator(model_opt='noise_opt')\n",
    "\n",
    "# Print the model summary\n",
    "print(model)\n",
    "\n",
    "trainer = Trainer(max_epochs=20)\n",
    "with mlflow.start_run() as run:\n",
    "    trainer.fit(model, train_dataloader, val_dataloader)\n",
    "\n",
    "# Save the model\n",
    "torch.save(model.state_dict(), '../models/state_estimator_20_epochs.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "mlruns_path = 'mlruns/0/' + run.info.run_id + '/metrics/'\n",
    "\n",
    "train_accuracy_path = mlruns_path + 'train_accuracy'\n",
    "train_loss_path = mlruns_path + 'train_loss'\n",
    "val_loss_path = mlruns_path + 'val_loss'\n",
    "\n",
    "# Load the metrics with pandas\n",
    "train_accuracy = pd.read_csv(train_accuracy_path ,sep=' ',header=None, names=[\"Time\", \"Accuracy\", \"Step\"])\n",
    "train_loss = pd.read_csv(train_loss_path ,sep=' ', names=[\"Time\", \"Train_Loss\", \"Step\"])\n",
    "val_loss = pd.read_csv(val_loss_path ,sep=' ', names=[\"Time\", \"Val_Loss\", \"Step\"])\n",
    "\n",
    "# Plot the metrics\n",
    "fig, ax = plt.subplots(1, 2, figsize=(15, 5))\n",
    "ax[0].plot(train_accuracy['Step'], train_accuracy['Accuracy'])\n",
    "ax[0].set_title('Training accuracy')\n",
    "ax[0].set_xlabel('Epoch')\n",
    "ax[0].set_ylabel('Accuracy')\n",
    "ax[1].plot(train_loss['Step'], train_loss['Train_Loss'], label='Training loss')\n",
    "ax[1].plot(val_loss['Step'], val_loss['Val_Loss'], label='Validation loss')\n",
    "ax[1].set_title('Training and validation loss')\n",
    "ax[1].set_xlabel('Epoch')\n",
    "ax[1].set_ylabel('Loss')\n",
    "ax[1].legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Load the saved model\n",
    "# model_weights = torch.load('../models/state_estimator.pt')\n",
    "\n",
    "# # Create a new model instance\n",
    "# model = StateEstimator(model_opt='noise_opt')\n",
    "\n",
    "# # Load the model weights\n",
    "# model.load_state_dict(model_weights)\n",
    "\n",
    "# # Set the model to evaluation mode\n",
    "# model.eval()\n",
    "\n",
    "# # Get a random index\n",
    "# random_idx = np.random.randint(0, validation_data_transpose.shape[0])\n",
    "\n",
    "# # Get the prediction\n",
    "# prediction = model(torch.from_numpy(validation_data_transpose[random_idx, :, :, :]).unsqueeze(0).float())\n",
    "\n",
    "# # Convert the tensor to numpy array for easier formatting\n",
    "# pred_array = prediction.detach().numpy()[0]  # Take the first row since prediction is 2D\n",
    "\n",
    "# # Using f-string for nicer printing\n",
    "# pred_str = \", \".join([f\"{val:.5f}\" for val in pred_array])\n",
    "# label_str = \", \".join([f\"{val:.5f}\" for val in validation_labels[random_idx]])\n",
    "\n",
    "# print(f\"Prediction: [{pred_str}]\")\n",
    "# print(f\"Label:      [{label_str}]\")\n",
    "\n",
    "# fig, ax = plt.subplots(1, 1, figsize=(5, 5))\n",
    "# ax.imshow(validation_data[random_idx, :, :, 0])\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from ml_tools.preprocessing.subimage_preprocessor import SubImagePreprocessor\n",
    "\n",
    "# # Get all the .npy files in the folder\n",
    "# data_files = glob.glob('../data/raw/data_qflow_v2/experimental/exp_small/dataset_0/*.npy')\n",
    "\n",
    "# print(data_files)\n",
    "\n",
    "# # extract only what we need from the data.\n",
    "# # note that there is no noise_class label for experimental data\n",
    "# exp_data = []; exp_labels = []\n",
    "# for f in data_files:\n",
    "#     d = np.load(f, allow_pickle=True).item()\n",
    "#     exp_data.append(d['sensor'])\n",
    "#     exp_labels.append(d['label'])\n",
    "\n",
    "# # convert only labels to list because exp_data contains different shaped data.\n",
    "# exp_labels = np.array(exp_labels)\n",
    "\n",
    "# # preprocess\n",
    "# # Autoflip because sensor gradient sign is unknown. \n",
    "# # Don't denoise because it doesn't help.\n",
    "# exp_prepper = SubImagePreprocessor(\n",
    "#     auto_invert=True,\n",
    "#     noise_reduction=[],\n",
    "#     clip_value=None,\n",
    "#     cutoff_value= None\n",
    "# )\n",
    "\n",
    "# proc_exp_data,exp_labels = exp_prepper.preprocess_subimages(exp_data,exp_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import torch.nn.functional as F\n",
    "\n",
    "# # Transpose the data to match the model input\n",
    "# proc_exp_data_transpose = np.transpose(proc_exp_data, (0, 3, 1, 2))\n",
    "\n",
    "# def compute_loss_and_accuracy(model, data, labels):\n",
    "#     # Convert the data and labels to PyTorch tensors\n",
    "#     data_tensor = torch.from_numpy(data).float()\n",
    "#     labels_tensor = torch.argmax(torch.from_numpy(labels), dim=1).long()\n",
    "\n",
    "#     # Pass the data through the model\n",
    "#     predictions = model(data_tensor)\n",
    "    \n",
    "#     # Compute the loss\n",
    "#     loss = F.cross_entropy(predictions, labels_tensor)\n",
    "    \n",
    "#     # Compute the accuracy\n",
    "#     predicted_labels = torch.argmax(predictions, dim=1)\n",
    "#     accuracy = (predicted_labels == labels_tensor).float().mean().item()\n",
    "    \n",
    "#     return loss.item(), accuracy\n",
    "\n",
    "# # Compute the loss and accuracy for the experimental data\n",
    "# exp_loss, exp_accuracy = compute_loss_and_accuracy(model, proc_exp_data_transpose, exp_labels)\n",
    "\n",
    "# print(f\"Experimental Data Loss: {exp_loss:.4f}\")\n",
    "# print(f\"Experimental Data Accuracy: {exp_accuracy*100:.2f}%\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "colibri",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
